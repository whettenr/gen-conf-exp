{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                             f1_score, \n",
    "                             precision_score, \n",
    "                             recall_score, \n",
    "                             roc_auc_score, \n",
    "                             roc_curve, \n",
    "                             accuracy_score)\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk import wordpunct_tokenize, word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "sw = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_data = pd.read_csv('cd_2011_2020_data.csv')\n",
    "gc_data\n",
    "authors_cleaned = []\n",
    "for author in gc_data.author:\n",
    "    authors_cleaned.append(author.replace(\"\\u00A0\",\" \"))\n",
    "gc_data.author = authors_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-588770b1e8fd>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  talks[\"target\"] = targets\n"
     ]
    }
   ],
   "source": [
    "talks = gc_data[gc_data.author.str.contains('Nelson|Monson|Uchtdorf|R. Holland|Bednar', regex=True)]\n",
    "\n",
    "targets = talks.apply(lambda x: x[0].split(' ')[-1], axis=1)\n",
    "talks[\"target\"] = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>President Russell M. Nelson</td>\n",
       "      <td>2020/04</td>\n",
       "      <td>My beloved brothers and sisters, as we welcome...</td>\n",
       "      <td>Nelson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>President Russell M. Nelson</td>\n",
       "      <td>2020/04</td>\n",
       "      <td>What a unique and wonderful session this has b...</td>\n",
       "      <td>Nelson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Elder Jeffrey R. Holland</td>\n",
       "      <td>2020/04</td>\n",
       "      <td>Last October, President Russell M. Nelson invi...</td>\n",
       "      <td>Holland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Elder David A. Bednar</td>\n",
       "      <td>2020/04</td>\n",
       "      <td>In the Sacred Grove 200 years ago, young Josep...</td>\n",
       "      <td>Bednar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>President Russell M. Nelson</td>\n",
       "      <td>2020/04</td>\n",
       "      <td>My dear brothers and sisters, how thankful I a...</td>\n",
       "      <td>Nelson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         author     date  \\\n",
       "0   President Russell M. Nelson  2020/04   \n",
       "21  President Russell M. Nelson  2020/04   \n",
       "24     Elder Jeffrey R. Holland  2020/04   \n",
       "25        Elder David A. Bednar  2020/04   \n",
       "26  President Russell M. Nelson  2020/04   \n",
       "\n",
       "                                                 text   target  \n",
       "0   My beloved brothers and sisters, as we welcome...   Nelson  \n",
       "21  What a unique and wonderful session this has b...   Nelson  \n",
       "24  Last October, President Russell M. Nelson invi...  Holland  \n",
       "25  In the Sacred Grove 200 years ago, young Josep...   Bednar  \n",
       "26  My dear brothers and sisters, how thankful I a...   Nelson  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(talks.shape)\n",
    "talks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-5621628756dd>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  talks[\"processed_text\"] = talks.text.apply(process_text)\n"
     ]
    }
   ],
   "source": [
    "wn = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def process_text(x):\n",
    "    x = x.lower()\n",
    "    tokens = wordpunct_tokenize(x)\n",
    "    tokens = [tok for tok in tokens if tok.isalnum()]\n",
    "    tokens = [tok for tok in tokens if tok not in sw]\n",
    "    tokens = [wn.lemmatize(tok) for tok in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "talks[\"processed_text\"] = talks.text.apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(talks, test_size=.3, \n",
    "                               stratify=talks.target, \n",
    "                               random_state=419)\n",
    "\n",
    "y_train = train['target']\n",
    "y_test = test['target']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9534\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=.005, stop_words=sw)\n",
    "tfidf.fit(train['processed_text'])\n",
    "print(len(tfidf.get_feature_names()))\n",
    "\n",
    "X_train = tfidf.transform(train['processed_text'])\n",
    "X_test = tfidf.transform(test['processed_text'])\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "yhat = nb.predict(X_test)\n",
    "y_prob = nb.predict_proba(X_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5490196078431373\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bednar' 'Holland' 'Monson' 'Nelson' 'Uchtdorf']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1,  0,  5],\n",
       "       [ 0,  0,  0,  0,  6],\n",
       "       [ 0,  0,  8,  1,  4],\n",
       "       [ 0,  0,  1,  6,  5],\n",
       "       [ 0,  0,  0,  0, 14]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(nb.classes_)\n",
    "confusion_matrix(y_test, yhat)\n",
    "# predicts most of talks as Uchtdorf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nelson_christmas = pd.read_csv('nelson_christmas.csv')\n",
    "nelson_christmas_vector = tfidf.transform(nelson_christmas['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Uchtdorf'], dtype='<U8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not correct: predicts uchtdorf not nelson\n",
    "nb.predict(nelson_christmas_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=-1),\n",
       "             param_grid={'max_depth': [5, 10, 50, 100, None],\n",
       "                         'n_estimators': [50, 250, 500]})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "parameters = {\n",
    "    'n_estimators': [50, 250, 500],\n",
    "    'max_depth': [5, 10, 50, 100, None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 100, 'n_estimators': 250}\n",
      "\n",
      "0.678 (+/-0.074) for {'max_depth': 5, 'n_estimators': 50}\n",
      "0.728 (+/-0.125) for {'max_depth': 5, 'n_estimators': 250}\n",
      "0.703 (+/-0.063) for {'max_depth': 5, 'n_estimators': 500}\n",
      "0.737 (+/-0.063) for {'max_depth': 10, 'n_estimators': 50}\n",
      "0.72 (+/-0.088) for {'max_depth': 10, 'n_estimators': 250}\n",
      "0.729 (+/-0.09) for {'max_depth': 10, 'n_estimators': 500}\n",
      "0.661 (+/-0.077) for {'max_depth': 50, 'n_estimators': 50}\n",
      "0.736 (+/-0.134) for {'max_depth': 50, 'n_estimators': 250}\n",
      "0.737 (+/-0.126) for {'max_depth': 50, 'n_estimators': 500}\n",
      "0.686 (+/-0.153) for {'max_depth': 100, 'n_estimators': 50}\n",
      "0.754 (+/-0.106) for {'max_depth': 100, 'n_estimators': 250}\n",
      "0.737 (+/-0.132) for {'max_depth': 100, 'n_estimators': 500}\n",
      "0.745 (+/-0.126) for {'max_depth': None, 'n_estimators': 50}\n",
      "0.72 (+/-0.18) for {'max_depth': None, 'n_estimators': 250}\n",
      "0.728 (+/-0.197) for {'max_depth': None, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print_results(cv)\n",
    "# 0.817 BEST PARAMS: {'max_depth': 50, 'n_estimators': 250}\n",
    "# 0.798 (+/-0.115) for {'max_depth': 50, 'n_estimators': 500}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8431372549019608\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=100, n_estimators=250, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "yhatrf = (rf.predict(X_test))\n",
    "print(accuracy_score(y_test, yhatrf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 2184 (0.011652)\n",
      "2. feature 6151 (0.008166)\n",
      "3. feature 508 (0.007388)\n",
      "4. feature 7990 (0.007344)\n",
      "5. feature 6429 (0.005751)\n",
      "6. feature 7780 (0.005681)\n",
      "7. feature 6077 (0.005626)\n",
      "8. feature 3559 (0.004546)\n",
      "9. feature 5316 (0.004406)\n",
      "10. feature 5526 (0.004235)\n",
      "\n",
      "\n",
      "dear\n",
      "perhaps\n",
      "amen\n",
      "spiritual\n",
      "prayer\n",
      "sister\n",
      "path\n",
      "found\n",
      "may\n",
      "month\n"
     ]
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "top_word_indicies = []\n",
    "for f in range(10):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    top_word_indicies.append(indices[f])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Print top features   \n",
    "for ind in top_word_indicies:\n",
    "    print(tfidf.get_feature_names()[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bednar' 'Holland' 'Monson' 'Nelson' 'Uchtdorf']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5,  0,  0,  1,  0],\n",
       "       [ 0,  3,  1,  0,  2],\n",
       "       [ 0,  0, 12,  0,  1],\n",
       "       [ 0,  0,  2,  8,  2],\n",
       "       [ 0,  0,  0,  0, 14]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rf.classes_)\n",
    "confusion_matrix(y_test, yhatrf)\n",
    "# Still predicts most of talks as Uchtdorf, but not as bad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nelson'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(nelson_christmas_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=AdaBoostClassifier(),\n",
       "             param_grid={'learning_rate': [0.2, 0.5, 1, 5, 10],\n",
       "                         'n_estimators': [300, 500, 700]})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [300, 500, 700],\n",
    "    'learning_rate': [.2, .5, 1, 5, 10]\n",
    "}\n",
    "cv = GridSearchCV(ada, parameters, cv=5)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'learning_rate': 0.5, 'n_estimators': 700}\n",
      "\n",
      "0.636 (+/-0.16) for {'learning_rate': 0.2, 'n_estimators': 300}\n",
      "0.652 (+/-0.134) for {'learning_rate': 0.2, 'n_estimators': 500}\n",
      "0.636 (+/-0.103) for {'learning_rate': 0.2, 'n_estimators': 700}\n",
      "0.619 (+/-0.202) for {'learning_rate': 0.5, 'n_estimators': 300}\n",
      "0.654 (+/-0.264) for {'learning_rate': 0.5, 'n_estimators': 500}\n",
      "0.678 (+/-0.191) for {'learning_rate': 0.5, 'n_estimators': 700}\n",
      "0.397 (+/-0.127) for {'learning_rate': 1, 'n_estimators': 300}\n",
      "0.397 (+/-0.127) for {'learning_rate': 1, 'n_estimators': 500}\n",
      "0.397 (+/-0.127) for {'learning_rate': 1, 'n_estimators': 700}\n",
      "0.577 (+/-0.146) for {'learning_rate': 5, 'n_estimators': 300}\n",
      "0.609 (+/-0.137) for {'learning_rate': 5, 'n_estimators': 500}\n",
      "0.551 (+/-0.309) for {'learning_rate': 5, 'n_estimators': 700}\n",
      "0.287 (+/-0.217) for {'learning_rate': 10, 'n_estimators': 300}\n",
      "0.185 (+/-0.151) for {'learning_rate': 10, 'n_estimators': 500}\n",
      "0.221 (+/-0.209) for {'learning_rate': 10, 'n_estimators': 700}\n"
     ]
    }
   ],
   "source": [
    "print_results(cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7843137254901961\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(learning_rate=0.5, n_estimators=700)\n",
    "ada.fit(X_train, y_train)\n",
    "yhatada = (ada.predict(X_test))\n",
    "print(accuracy_score(y_test, yhatada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bednar' 'Holland' 'Monson' 'Nelson' 'Uchtdorf']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2,  0,  1,  1,  2],\n",
       "       [ 0,  3,  3,  0,  0],\n",
       "       [ 0,  0, 11,  1,  1],\n",
       "       [ 0,  0,  0, 10,  2],\n",
       "       [ 0,  0,  0,  0, 14]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ada.classes_)\n",
    "confusion_matrix(y_test, yhatada)\n",
    "# Still predicts most of talks as Uchtdorf, but not as bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nelson'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.predict(nelson_christmas_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
